#### 热点key是啥？

应该听名字就可以理解，就是频繁被访问的数据，例如热点新闻，热点评论，双十一商品等等

热点数据对服务器来说，是一个巨大的隐患，以redis-cluster 来说，它可能会造成整体流量不均衡，个别ops过大的情况，极端的情况下，可能直接超过redis本事的承受能力。

## 热点key的发现方案

#### 客户端代码统计

- 有代码入侵，且维护成本较高
- 大规模落地肯定不合适
- 万一热点key多了，还有可能oom

#### 凭借经验，进行预估：例如提前知道了某个活动的开启，那么就将此Key作为热点Key

- 得有这个经验啊~，也不是每个人都有这个经验的吧

#### 在proxy层，对每个请求进行收集上报

- 代理层做的话，首先，得用了代理~例如codis之类的
- 需要做二次开发，肯定就得投入人力
- 改proxy源码，不论难不难，都要考虑一个稳定性和维护成本

#### Redis-cli --hotkyes 查询热点key

但是这个只适用于缓存淘汰策略是lfu的时候（only works when maxmemory-policy is *lfu.）

可以参考<https://yq.aliyun.com/articles/278922>

#### monitor 命令

![屏幕快照 2019-07-28 上午10.23.57](../../../../../%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-07-28%20%E4%B8%8A%E5%8D%8810.23.57.png)

monitor 命令可以监控redis执行的所有命令，其模型（）：

![屏幕快照 2019-07-28 上午10.31.12](../../../../../%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-07-28%20%E4%B8%8A%E5%8D%8810.31.12.png)

EdrawMax画的图，如果你不常用的话，可以用process on



利用monitor的结果，统计出一段时间内的热点key的各项排行指数

Facebook的redis-faina也是用的monitor机制来实现的；

缺点：

- monitor命令在高并发的场景下，会存在内存暴增，影响redis的性能，只适合短时间的统计，不适合一直使用
- 只能统计单节点的热点key，对于集群需要进行汇总统计



#### TCP消息抓包

Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。如果站在机器的角度，可以通过对机器上所有Redis端口的TCP数据包进行抓取完成热点key的统计

此种方法对于Redis客户端和服务端来说毫无侵入，是比较完美的方案，但是依然存在3个问题：

(1) 需要一定的开发成本，但是一些开源方案实现了该功能，例如ELK(ElasticSearch Logstash Kibana)体系下的packetbeat[2] 插件，可以实现对Redis、MySQL等众多主流服务的数据包抓取、分析、报表展示

(2) 对于高流量的机器抓包，对机器网络可能会有干扰，同时抓包时候会有丢包的可能性。

(3) 维护成本过高。



#### 三种解决热点key问题的思路

(1) 拆分复杂数据结构： 如果当前key的类型是一个二级数据结构，例如哈希类型。如果该哈希元素个数较多，可以考虑将当前hash进行拆分，这样该热点key可以拆分为若干个新的key分布到不同Redis节点上，从而减轻压力。

(2) 迁移热点key：以Redis Cluster为例，可以将热点key所在的slot单独迁移到一个新的Redis节点上

(3) 本地缓存加通知机制：可以将热点key放在业务端的本地缓存中，因为是在业务端的本地内存中，处理能力要高出Redis数十倍，但当数据更新时，此种模式会造成各个业务端和Redis数据不一致，通常会使用发布订阅机制来解决类似问题。





本文参考文章:<https://cachecloud.github.io/>

